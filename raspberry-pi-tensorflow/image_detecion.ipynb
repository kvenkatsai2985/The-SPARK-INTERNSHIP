{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e9411b0",
   "metadata": {},
   "source": [
    "# GRIP - The Spark Foundation\n",
    "# Computer Vision & Internet Of Things\n",
    "# Author : K.Venkata Sree Sai\n",
    "# Task 1 : Object Detection using Open CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mYUPLO_UysSI",
   "metadata": {
    "id": "mYUPLO_UysSI"
   },
   "source": [
    "# Live Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d32281",
   "metadata": {
    "id": "45d32281"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar modelos\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")\n",
    "labels = pd.read_csv('labels.csv',sep=';',index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = 512\n",
    "height = 512\n",
    "\n",
    "while(True):\n",
    "    #Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #Resize to respect the input_shape\n",
    "    inp = cv2.resize(frame, (width , height ))\n",
    "\n",
    "    #Convert img to RGB\n",
    "    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "    rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "\n",
    "    #Add dims to rgb_tensor\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "    \n",
    "    boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    "    \n",
    "    pred_labels = classes.numpy().astype('int')[0]\n",
    "    \n",
    "    pred_labels = [labels[i] for i in pred_labels]\n",
    "    pred_boxes = boxes.numpy()[0].astype('int')\n",
    "    pred_scores = scores.numpy()[0]\n",
    "    #loop throughout the faces detected and place a box around it\n",
    "    \n",
    "    for score, (ymin,xmin,ymax,xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "            \n",
    "        score_txt = f'{100 * round(score,0)}'\n",
    "        img_boxes = cv2.rectangle(rgb,(xmin, ymax),(xmax, ymin),(0,255,0),1)      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_boxes,label,(xmin, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(img_boxes,score_txt,(xmax, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    #Display the resulting frame\n",
    "    cv2.imshow('black and white',img_boxes)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRhDMi8zyvvt",
   "metadata": {
    "id": "XRhDMi8zyvvt"
   },
   "source": [
    "# Static Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a661bd",
   "metadata": {
    "id": "96a661bd"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2897b6f",
   "metadata": {
    "id": "b2897b6f"
   },
   "outputs": [],
   "source": [
    "# Apply image detector on a batch of image.\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d520f43a",
   "metadata": {
    "id": "d520f43a"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-sn_xpupm\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Resize to respect the input_shape\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Convert img to RGB\u001b[39;00m\n\u001b[0;32m     10\u001b[0m rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(inp, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-sn_xpupm\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "width = 1028\n",
    "height = 1028\n",
    "\n",
    "#Load image by Opencv2\n",
    "img = cv2.imread('image.jpg')\n",
    "#Resize to respect the input_shape\n",
    "inp = cv2.resize(img, (width,height))\n",
    "\n",
    "#Convert img to RGB\n",
    "rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "\n",
    "#Add dims to rgb_tensor\n",
    "rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "\n",
    "#Now you can use rgb_tensor to predict label for exemple :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0gI58cWnp5EH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "0gI58cWnp5EH",
    "outputId": "f09e2457-6b0c-4f65-8304-bc0d744e7032"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb5c51",
   "metadata": {
    "id": "b4fb5c51"
   },
   "outputs": [],
   "source": [
    "boxes, scores, classes, num_detections = detector(rgb_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1872f22",
   "metadata": {
    "id": "b1872f22"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv',sep=';',index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62da431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b62da431",
    "outputId": "b0f9bdc0-3a59-410f-8f2c-5a9cbc6b6028"
   },
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5493c54",
   "metadata": {
    "id": "a5493c54"
   },
   "outputs": [],
   "source": [
    "pred_labels = classes.numpy().astype('int')[0] \n",
    "pred_labels = [labels[i] for i in pred_labels]\n",
    "pred_boxes = boxes.numpy()[0].astype('int')\n",
    "pred_scores = scores.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd11e8",
   "metadata": {
    "id": "23bd11e8"
   },
   "outputs": [],
   "source": [
    "for score, (ymin,xmin,ymax,xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "            \n",
    "        score_txt = f'{100 * round(score)}%'\n",
    "        img_boxes = cv2.rectangle(rgb,(xmin, ymax),(xmax, ymin),(0,255,0),2)      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_boxes, label,(xmin, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(img_boxes,score_txt,(xmax, ymax-10), font, 1.5, (255,0,0), 2, cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61d3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "85a61d3f",
    "outputId": "c02a1f5f-c7a0-4c3c-b9b3-f04feaa1a27f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_boxes)\n",
    "\n",
    "plt.savefig('image_pred.jpg',transparent=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2l2QswiwNSn",
   "metadata": {
    "id": "f2l2QswiwNSn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b0e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_detecion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
